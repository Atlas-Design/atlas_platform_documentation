"use strict";(self.webpackChunkatlas_platform_documentation=self.webpackChunkatlas_platform_documentation||[]).push([[3462],{510:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/image_to_text-bc1ad7a4acd2ffdc20cad4d438d11933.png"},1642:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"workflows/2d-variants","title":"2D Variants","description":"This workflow creates 2D variations of an input asset image by transforming it across different environments, styles, forms, or time periods.","source":"@site/docs/workflows/2d-variants.mdx","sourceDirName":"workflows","slug":"/workflows/2d-variants","permalink":"/atlas_platform_documentation/workflows/2d-variants","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"2d-variants","title":"2D Variants","sidebar_label":"2D Variants"},"sidebar":"mainSidebar","previous":{"title":"Image to Spline","permalink":"/atlas_platform_documentation/workflows/image-to-spline"},"next":{"title":"Asset Segmentation","permalink":"/atlas_platform_documentation/workflows/asset-segmentation"}}');var s=t(4848),r=t(8453);const a={id:"2d-variants",title:"2D Variants",sidebar_label:"2D Variants"},o="2D Variants Workflow",l={},d=[{value:"1. Input Asset &amp; Define Variation Type",id:"1-input-asset--define-variation-type",level:2},{value:"2. Image Description (Image-to-Text Node)",id:"2-image-description-image-to-text-node",level:2},{value:"3. Generate Transformation Prompts (Simple LLM Call)",id:"3-generate-transformation-prompts-simple-llm-call",level:2},{value:"4. Generate Visual Variants (Multimodal Node)",id:"4-generate-visual-variants-multimodal-node",level:2},{value:"Summary",id:"summary",level:2}];function c(e){const n={br:"br",h1:"h1",h2:"h2",header:"header",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"2d-variants-workflow",children:"2D Variants Workflow"})}),"\n",(0,s.jsxs)(n.p,{children:["This workflow creates ",(0,s.jsx)(n.strong,{children:"2D variations"})," of an input asset image by transforming it across different environments, styles, forms, or time periods.",(0,s.jsx)(n.br,{}),"\n","The system analyzes the original object, interprets your desired variation type, and produces multiple transformed outputs reflecting alternative scenarios."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"1-input-asset--define-variation-type",children:"1. Input Asset & Define Variation Type"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.img,{alt:"step-image",src:t(9299).A+"",width:"1536",height:"1024"}),"\r\n",(0,s.jsx)(n.img,{alt:"step-image",src:t(9627).A+"",width:"732",height:"835"})]}),"\n",(0,s.jsxs)(n.p,{children:["Begin by uploading an ",(0,s.jsx)(n.strong,{children:"image of the asset"})," you want to modify.",(0,s.jsx)(n.br,{}),"\n","Then specify the ",(0,s.jsx)(n.strong,{children:"variation type"}),", such as:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Environment"}),"\n",(0,s.jsx)(n.li,{children:"Style"}),"\n",(0,s.jsx)(n.li,{children:"Form"}),"\n",(0,s.jsx)(n.li,{children:"Time period"}),"\n",(0,s.jsx)(n.li,{children:"Condition (weather, damage, decay, futuristic upgrade)"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["In the example shown, we requested an ",(0,s.jsx)(n.strong,{children:"environmental variation"})," of the input asset."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"2-image-description-image-to-text-node",children:"2. Image Description (Image-to-Text Node)"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"step-image",src:t(510).A+"",width:"1137",height:"536"})}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.strong,{children:"Image-to-Text"})," node analyzes the input asset and generates a ",(0,s.jsx)(n.strong,{children:"clear description"})," of its form, materials, and functional features."]}),"\n",(0,s.jsx)(n.p,{children:"This description is used as an objective baseline for creating consistent variant prompts."}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"3-generate-transformation-prompts-simple-llm-call",children:"3. Generate Transformation Prompts (Simple LLM Call)"}),"\n",(0,s.jsxs)(n.p,{children:["A ",(0,s.jsx)(n.strong,{children:"Simple LLM Call"})," node takes:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"The image description (from Image-to-Text)"}),"\n",(0,s.jsx)(n.li,{children:"The variation type you specify (e.g., \u201cenvironment\u201d)"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["It then generates ",(0,s.jsx)(n.strong,{children:"four transformation prompts"}),", each exploring a different environmental adaptation."]}),"\n",(0,s.jsx)(n.p,{children:"Example outputs for an \u201cenvironment\u201d variation:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Desert adaptation"}),"\n",(0,s.jsx)(n.li,{children:"Tropical rainforest adaptation"}),"\n",(0,s.jsx)(n.li,{children:"Arctic tundra adaptation"}),"\n",(0,s.jsx)(n.li,{children:"Urban night-operation adaptation"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Each prompt may involve:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Adjusting form"}),"\n",(0,s.jsx)(n.li,{children:"Adding contextual elements"}),"\n",(0,s.jsx)(n.li,{children:"Modifying materials to fit the new environment"}),"\n",(0,s.jsx)(n.li,{children:"Reinterpreting design language"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"These prompts define how the asset should change in each scenario."}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"4-generate-visual-variants-multimodal-node",children:"4. Generate Visual Variants (Multimodal Node)"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"step-image",src:t(3716).A+"",width:"1250",height:"1250"})}),"\n",(0,s.jsxs)(n.p,{children:["Each transformation prompt is passed to a ",(0,s.jsx)(n.strong,{children:"Multimodal node"}),", which produces the final ",(0,s.jsx)(n.strong,{children:"2D image variants"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"The outputs may reflect:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Environmental adaptation"}),"\n",(0,s.jsx)(n.li,{children:"Style transformation"}),"\n",(0,s.jsx)(n.li,{children:"New functionality"}),"\n",(0,s.jsx)(n.li,{children:"Material and color shifts"}),"\n",(0,s.jsx)(n.li,{children:"Added props or contextual features"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["The result is a ",(0,s.jsx)(n.strong,{children:"set of variant images"}),", each representing a different reinterpretation of the original asset."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Stage"}),(0,s.jsx)(n.th,{children:"Description"}),(0,s.jsx)(n.th,{children:"Output"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Input Image + Variation Type"}),(0,s.jsx)(n.td,{children:"User-provided image and variation category"}),(0,s.jsx)(n.td,{children:"Asset + variation goal"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Image-to-Text"}),(0,s.jsx)(n.td,{children:"Describes the object\u2019s appearance"}),(0,s.jsx)(n.td,{children:"Baseline description"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Simple LLM Call"}),(0,s.jsx)(n.td,{children:"Creates transformation prompts"}),(0,s.jsx)(n.td,{children:"4 variation prompts"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Multimodal"}),(0,s.jsx)(n.td,{children:"Generates variations"}),(0,s.jsx)(n.td,{children:"4 variant images"})]})]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.p,{children:"This workflow is ideal for concept art, iterative design exploration, and testing how an object behaves across different worlds, styles, or narrative contexts."})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},3716:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/multimodal_variants-318d7bf115681e300cb32f51c0c2e68b.jpg"},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>o});var i=t(6540);const s={},r=i.createContext(s);function a(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),i.createElement(r.Provider,{value:n},e.children)}},9299:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/input-83f00d5d83fc6847c807a046bbd44177.png"},9627:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/text_input-c1b0137ec367fcef37512732d7562139.png"}}]);